---
phase: 05-policy-integrity
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/decisiongraph/engine.py
  - src/decisiongraph/policyhead.py
  - tests/test_engine_promotion.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Promotion fails with DG_INPUT_INVALID if rule_ids contain rules from different namespace"
    - "policy_hash is verified at finalization time before PolicyHead creation"
    - "Concurrent promotions for same namespace detect race condition via prev_policy_head validation"
  artifacts:
    - path: "src/decisiongraph/engine.py"
      provides: "Namespace validation in submit_promotion, race detection in finalize_promotion"
      contains: "rule_cell.fact.namespace != namespace"
    - path: "src/decisiongraph/policyhead.py"
      provides: "verify_policy_hash function"
      exports: ["verify_policy_hash"]
    - path: "tests/test_engine_promotion.py"
      provides: "Tests for INT-02, INT-03, and race condition detection"
      min_lines: 500
  key_links:
    - from: "src/decisiongraph/engine.py:submit_promotion"
      to: "chain.get_cell()"
      via: "Lookup each rule_id to validate namespace"
      pattern: "chain\\.get_cell\\(rule_id\\)"
    - from: "src/decisiongraph/engine.py:finalize_promotion"
      to: "verify_policy_hash"
      via: "Hash verification before append"
      pattern: "verify_policy_hash"
---

<objective>
Add namespace validation to submit_promotion() (INT-03), policy_hash runtime verification to finalize_promotion() (INT-02), and concurrent promotion race detection via prev_policy_head validation.

Purpose: Protect against invalid operations - cannot promote rules from wrong namespace, cannot finalize with tampered policy_hash, and cannot have silent race conditions between concurrent promotions.

Output: Modified engine.py with validation logic, tests proving each validation case works correctly.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-policy-integrity/05-RESEARCH.md

# Source files to modify
@src/decisiongraph/engine.py
@src/decisiongraph/policyhead.py
@tests/test_engine_promotion.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add namespace validation to submit_promotion()</name>
  <files>src/decisiongraph/engine.py</files>
  <action>
Add namespace validation to submit_promotion() method (INT-03). For each rule_id in rule_ids:
1. Look up the rule cell using self.chain.get_cell(rule_id)
2. If rule_cell is None, raise InputInvalidError with message "Rule {rule_id} not found"
3. If rule_cell.fact.namespace != namespace, raise InputInvalidError with message like "Rule {rule_id} is from namespace {rule_cell.fact.namespace}, expected {namespace}"

This validation should happen BEFORE looking up the WitnessSet (fail fast principle).

Also store expected_prev_policy_head in PromotionRequest for race detection (requires modifying PromotionRequest.create() call to include current policy head at submit time). Add a field to PromotionRequest or store it in a separate dict keyed by promotion_id.

Implementation detail: Store the expected prev_policy_head in a dict on Engine: self._expected_prev_policy_head[promotion_id] = current_policy_head_id or store it on the PromotionRequest.

Pattern to follow (from research):
```python
# Validate each rule_id belongs to namespace
for rule_id in rule_ids:
    rule_cell = self.chain.get_cell(rule_id)
    if rule_cell is None:
        raise InputInvalidError(
            message=f"Rule {rule_id} not found",
            details={"rule_id": rule_id, "namespace": namespace}
        )
    if rule_cell.fact.namespace != namespace:
        raise InputInvalidError(
            message=f"Rule {rule_id} is from namespace {rule_cell.fact.namespace}, expected {namespace}",
            details={
                "rule_id": rule_id,
                "rule_namespace": rule_cell.fact.namespace,
                "expected_namespace": namespace
            }
        )
```
  </action>
  <verify>Run `pytest tests/test_engine_promotion.py -v` - existing tests should still pass (no rules being looked up in current tests, so validation is skipped for empty/non-existent rules if we gate on rule_ids list being non-empty)</verify>
  <done>submit_promotion() validates all rule_ids are from the target namespace before creating PromotionRequest</done>
</task>

<task type="auto">
  <name>Task 2: Add race detection and policy_hash verification to finalize_promotion()</name>
  <files>src/decisiongraph/engine.py, src/decisiongraph/policyhead.py</files>
  <action>
Add two validations to finalize_promotion() method:

**A) Race condition detection (before PolicyHead creation):**
1. Get current policy head using get_current_policy_head(self.chain, promotion.namespace)
2. Retrieve expected prev_policy_head that was stored at submit time
3. Compare: if expected is not None AND current differs from expected, another promotion was finalized
4. Raise InputInvalidError with message "Concurrent promotion detected. Expected prev_policy_head {expected}, but current is {actual}"
5. Handle edge case: if expected was None (first promotion) and current is also None, NOT a race condition

**B) Policy hash verification (after PolicyHead creation, before append):**
1. After creating policy_head via create_policy_head(), call verify_policy_hash(policy_head)
2. If verification fails, raise IntegrityFailError with message "PolicyHead policy_hash verification failed"
3. This catches any tampering between creation and append

Import IntegrityFailError from exceptions module.

Pattern for race detection:
```python
# At submit time (store expected):
current_ph = get_current_policy_head(self.chain, namespace)
expected_prev_id = current_ph.cell_id if current_ph else None
# Store expected_prev_id for this promotion

# At finalize time (check for race):
current_policy_head = get_current_policy_head(self.chain, promotion.namespace)
current_head_id = current_policy_head.cell_id if current_policy_head else None
expected_prev = # retrieve stored expected for this promotion_id

# Race detection: only flag if expected was set AND differs
if expected_prev is not None and current_head_id != expected_prev:
    raise InputInvalidError(
        message=f"Concurrent promotion detected. Expected prev_policy_head {expected_prev}, but current is {current_head_id}",
        details={...}
    )
# Also flag if expected was None but now there's a head (someone promoted first)
if expected_prev is None and current_head_id is not None:
    raise InputInvalidError(
        message=f"Concurrent promotion detected. Expected no previous policy, but found {current_head_id}",
        details={...}
    )
```
  </action>
  <verify>Run `pytest tests/test_engine_promotion.py -v` - existing tests pass (they don't trigger race conditions)</verify>
  <done>finalize_promotion() detects concurrent promotions via prev_policy_head comparison and verifies policy_hash before chain append</done>
</task>

<task type="auto">
  <name>Task 3: Add tests for INT-02, INT-03, and race detection</name>
  <files>tests/test_engine_promotion.py</files>
  <action>
Add new test class TestPolicyIntegrity with tests:

**INT-03 Tests (namespace validation):**
1. test_submit_promotion_rule_not_found - rule_id doesn't exist in chain, expect InputInvalidError
2. test_submit_promotion_rule_wrong_namespace - rule_id exists but is from different namespace, expect InputInvalidError with message containing namespace mismatch
3. test_submit_promotion_mixed_namespaces - some rules from correct namespace, one from wrong, expect InputInvalidError

**INT-02 Tests (policy_hash verification):**
1. test_finalize_verifies_policy_hash - normal case passes (implicit, existing tests cover)
2. Note: Testing hash verification failure requires tampering with cell internals, which may not be testable without mocking. Document this as "verified by code inspection" if needed.

**Race Detection Tests:**
1. test_concurrent_promotion_race_detected - submit promotion A, finalize promotion B (different promotion), then try to finalize A - should fail with race detection
2. test_first_promotion_no_race_false_positive - first promotion for namespace should succeed (no prev_policy_head expected or actual)

To create test data (rule cells), use create_decision_cell from cell.py or create facts that can be looked up. May need helper function.

Example test structure:
```python
class TestPolicyIntegrity:
    """Tests for INT-02, INT-03, and race detection"""

    def test_submit_promotion_rule_not_found(self):
        """Rule ID not in chain raises InputInvalidError (INT-03)."""
        chain = create_test_chain_with_witnesses(["alice"], 1)
        engine = Engine(chain)

        with pytest.raises(InputInvalidError) as exc_info:
            engine.submit_promotion(
                namespace="corp",
                rule_ids=["rule:nonexistent"],  # Not in chain
                submitter_id="alice"
            )
        assert "not found" in exc_info.value.message
        assert exc_info.value.code == "DG_INPUT_INVALID"

    def test_submit_promotion_rule_wrong_namespace(self):
        """Rule from wrong namespace raises InputInvalidError (INT-03)."""
        # Create chain with rule in "other" namespace
        chain = create_test_chain_with_witnesses(["alice"], 1)
        # Add a rule cell to "other" namespace
        rule_cell = create_rule_cell("other", "rule:other_rule")
        chain.append(rule_cell)
        engine = Engine(chain)

        with pytest.raises(InputInvalidError) as exc_info:
            engine.submit_promotion(
                namespace="corp",  # Target namespace
                rule_ids=[rule_cell.cell_id],  # Rule from "other" namespace
                submitter_id="alice"
            )
        assert "other" in exc_info.value.message
        assert "corp" in exc_info.value.message
        assert exc_info.value.code == "DG_INPUT_INVALID"
```
  </action>
  <verify>Run `pytest tests/test_engine_promotion.py::TestPolicyIntegrity -v` - all new tests pass</verify>
  <done>All INT-02, INT-03, and race detection scenarios have test coverage</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `pytest tests/test_engine_promotion.py -v` - all tests pass (existing + new)
2. `pytest tests/ -v --tb=short` - no regressions in other test files
3. Verify INT-03: submit_promotion rejects rules from wrong namespace
4. Verify INT-02: policy_hash verified at finalize time (code inspection)
5. Verify race detection: concurrent promotions detected via prev_policy_head comparison
</verification>

<success_criteria>
1. submit_promotion() raises InputInvalidError with DG_INPUT_INVALID for rules from different namespace
2. submit_promotion() raises InputInvalidError with DG_INPUT_INVALID for rules not found in chain
3. finalize_promotion() calls verify_policy_hash() before chain append
4. finalize_promotion() detects concurrent promotion via prev_policy_head mismatch
5. All existing tests continue to pass (no regressions)
6. New tests cover all validation failure cases
</success_criteria>

<output>
After completion, create `.planning/phases/05-policy-integrity/05-01-SUMMARY.md`
</output>
