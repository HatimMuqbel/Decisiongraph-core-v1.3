---
phase: 10-counterfactual-anchors
plan: 02
type: execute
wave: 2
depends_on: ["10-01"]
files_modified:
  - src/decisiongraph/engine.py
  - src/decisiongraph/simulation.py
  - tests/test_anchors.py
autonomous: true

must_haves:
  truths:
    - "Engine.simulate_rfa() populates anchors field in SimulationResult when verdict_changed=True"
    - "Anchors are empty when verdict_changed=False (no delta to explain)"
    - "Anchor detection respects max_anchor_attempts and max_runtime_ms bounds"
    - "anchors_incomplete=True returned when execution budget exceeded"
    - "Same simulation spec always produces identical anchor results (determinism)"
  artifacts:
    - path: "src/decisiongraph/engine.py"
      provides: "Updated simulate_rfa() calling detect_counterfactual_anchors"
      contains: "detect_counterfactual_anchors"
    - path: "tests/test_anchors.py"
      provides: "Comprehensive anchor detection tests"
      min_lines: 200
  key_links:
    - from: "src/decisiongraph/engine.py"
      to: "src/decisiongraph/anchors.py"
      via: "import detect_counterfactual_anchors"
      pattern: "from .anchors import"
    - from: "src/decisiongraph/engine.py"
      to: "SimulationResult.anchors"
      via: "passes anchor result to SimulationResult constructor"
      pattern: "anchors=.*anchor_result"
---

<objective>
Integrate anchor detection into Engine.simulate_rfa() and create comprehensive test suite for all CTF requirements.

Purpose: Complete Phase 10 by wiring anchor detection into the simulation pipeline and validating all requirements (CTF-01 through CTF-04) with tests.

Output: Updated Engine.simulate_rfa() that calls detect_counterfactual_anchors() when verdict_changed=True, plus test_anchors.py with comprehensive test coverage.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-counterfactual-anchors/10-01-PLAN.md
@.planning/phases/10-counterfactual-anchors/10-RESEARCH.md
@src/decisiongraph/anchors.py
@src/decisiongraph/engine.py
@src/decisiongraph/simulation.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate Anchor Detection into Engine.simulate_rfa()</name>
  <files>src/decisiongraph/engine.py</files>
  <action>
Update Engine.simulate_rfa() to call detect_counterfactual_anchors():

1. Add import at top of engine.py:
   ```python
   from .anchors import detect_counterfactual_anchors, AnchorResult
   ```

2. Update simulate_rfa() signature to accept optional anchor bounds:
   ```python
   def simulate_rfa(
       self,
       rfa_dict: dict,
       simulation_spec: dict,
       at_valid_time: str,
       as_of_system_time: str,
       max_anchor_attempts: int = 100,
       max_runtime_ms: int = 5000
   ) -> SimulationResult:
   ```

3. After Step 9 (compute_delta_report), add Step 9.5 for anchor detection:
   ```python
   # Step 9.5: Detect counterfactual anchors if verdict changed (CTF-02, CTF-03, CTF-04)
   if delta_report.verdict_changed:
       anchor_result = detect_counterfactual_anchors(
           engine=self,
           rfa_dict=canonical_rfa,
           base_result=base_result,
           simulation_spec=simulation_spec,
           at_valid_time=at_valid_time,
           as_of_system_time=as_of_system_time,
           max_anchor_attempts=max_anchor_attempts,
           max_runtime_ms=max_runtime_ms
       )
       anchors_dict = anchor_result.to_dict()
   else:
       # No verdict change = no anchors to detect
       anchors_dict = {
           'anchors': [],
           'anchors_incomplete': False,
           'attempts_used': 0,
           'runtime_ms': 0.0,
           'anchor_hash': ''
       }
   ```

4. Update Step 13 (SimulationResult creation) to use anchors_dict:
   ```python
   return SimulationResult(
       ...
       anchors=anchors_dict,  # Was {} in Phase 9
       ...
   )
   ```

5. Update docstring to document anchor-related parameters:
   - max_anchor_attempts: Max simulation attempts for anchor detection (default 100)
   - max_runtime_ms: Max runtime for anchor detection in milliseconds (default 5000)
   - Note that anchors populated only when verdict_changed=True
  </action>
  <verify>
python -c "from decisiongraph import Engine; print('Engine imports with anchor support')"
  </verify>
  <done>
Engine.simulate_rfa() calls detect_counterfactual_anchors() when verdict_changed=True. Passes max_anchor_attempts and max_runtime_ms bounds. Returns populated anchors dict in SimulationResult.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Comprehensive Anchor Detection Tests</name>
  <files>tests/test_anchors.py</files>
  <action>
Create tests/test_anchors.py with comprehensive test coverage:

```python
"""
Tests for counterfactual anchor detection (Phase 10).

Requirements tested:
- CTF-01: Deterministic anchor hashing (sorted components)
- CTF-02: Bounded execution (max_anchor_attempts, max_runtime_ms)
- CTF-03: Minimal shadow components causing verdict delta
- CTF-04: anchors_incomplete=True when budget exceeded
"""
```

Test categories needed:

1. ExecutionBudget tests:
   - test_execution_budget_tracks_attempts
   - test_execution_budget_tracks_time
   - test_execution_budget_exceeded_by_attempts
   - test_execution_budget_exceeded_by_time
   - test_execution_budget_not_exceeded

2. AnchorResult tests:
   - test_anchor_result_frozen
   - test_anchor_result_to_dict
   - test_anchor_result_with_incomplete_flag

3. compute_anchor_hash tests:
   - test_anchor_hash_deterministic
   - test_anchor_hash_different_for_different_anchors
   - test_anchor_hash_same_for_reordered_anchors

4. detect_counterfactual_anchors tests:
   - test_no_shadow_components_returns_empty_anchors
   - test_single_shadow_fact_is_anchor
   - test_minimal_anchor_found (multiple components, only one causes delta)
   - test_anchors_incomplete_when_attempts_exceeded
   - test_anchors_incomplete_when_timeout_exceeded
   - test_anchor_detection_deterministic (same spec = same anchors)
   - test_no_anchors_when_verdict_unchanged

5. Engine integration tests:
   - test_simulate_rfa_populates_anchors_when_verdict_changed
   - test_simulate_rfa_empty_anchors_when_verdict_unchanged
   - test_simulate_rfa_respects_max_anchor_attempts
   - test_simulate_rfa_respects_max_runtime_ms

Test fixtures needed:
- Create chain with namespace, bridge, rule, facts
- Create simulation_spec with shadow facts that cause verdict change
- Create simulation_spec with shadow facts that don't change verdict
- Helper to build chain similar to test_simulation.py fixtures

Use existing test patterns from tests/test_simulation.py for fixture setup.
Import get_current_timestamp from decisiongraph.cell for timestamp generation.
  </action>
  <verify>
pytest tests/test_anchors.py -v 2>&1 | tail -30
  </verify>
  <done>
Comprehensive test suite covering all CTF requirements. ExecutionBudget, AnchorResult, compute_anchor_hash, detect_counterfactual_anchors, and Engine integration all tested. Tests validate bounded execution, determinism, and minimal anchor detection.
  </done>
</task>

<task type="auto">
  <name>Task 3: Run Full Test Suite and Verify Requirements</name>
  <files>tests/test_anchors.py</files>
  <action>
1. Run full test suite to verify no regressions:
   ```bash
   pytest tests/ -x -q
   ```
   Expected: All tests pass (846 existing + new anchor tests)

2. Verify specific CTF requirements with targeted tests:
   - CTF-01: test_anchor_hash_deterministic, test_anchor_detection_deterministic
   - CTF-02: test_execution_budget_exceeded_by_attempts, test_execution_budget_exceeded_by_time
   - CTF-03: test_minimal_anchor_found, test_single_shadow_fact_is_anchor
   - CTF-04: test_anchors_incomplete_when_attempts_exceeded, test_anchors_incomplete_when_timeout_exceeded

3. Verify Engine integration:
   - test_simulate_rfa_populates_anchors_when_verdict_changed
   - test_simulate_rfa_empty_anchors_when_verdict_unchanged

4. Count total tests and confirm test file structure:
   ```bash
   pytest tests/test_anchors.py --collect-only -q
   ```
  </action>
  <verify>
pytest tests/ -x -q 2>&1 | tail -5
  </verify>
  <done>
All tests pass (846 existing + new anchor tests). CTF-01, CTF-02, CTF-03, CTF-04 all verified by tests. Engine.simulate_rfa() integration working correctly.
  </done>
</task>

</tasks>

<verification>
After all tasks:
1. Engine.simulate_rfa() calls detect_counterfactual_anchors() when verdict_changed=True
2. SimulationResult.anchors populated with anchor detection results
3. max_anchor_attempts and max_runtime_ms respected (CTF-02)
4. anchors_incomplete=True when budget exceeded (CTF-04)
5. Minimal anchors detected correctly (CTF-03)
6. Anchor hash deterministic (CTF-01 extension)
7. All tests pass (existing 846 + new anchor tests)
</verification>

<success_criteria>
- [ ] Engine.simulate_rfa() accepts max_anchor_attempts and max_runtime_ms parameters
- [ ] Anchor detection runs only when verdict_changed=True
- [ ] SimulationResult.anchors contains anchor_result.to_dict()
- [ ] tests/test_anchors.py with 15+ tests covering all CTF requirements
- [ ] ExecutionBudget bounds enforced (CTF-02)
- [ ] anchors_incomplete flag set correctly (CTF-04)
- [ ] Minimal anchor detected via greedy ablation (CTF-03)
- [ ] All existing 846 tests pass
- [ ] Total test count increased by anchor tests
</success_criteria>

<output>
After completion, create `.planning/phases/10-counterfactual-anchors/10-02-SUMMARY.md`
</output>
